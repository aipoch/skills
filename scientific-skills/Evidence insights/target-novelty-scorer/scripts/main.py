#!/usr/bin/env python3
"""
Target Novelty Scorer
åŸºäºæ–‡çŒ®æŒ–æ˜çš„é¶ç‚¹æ–°é¢–åº¦è¯„åˆ†å·¥å…·

Usage:
    python main.py --target "PD-L1"
    python main.py --target "BRCA1" --years 10 --format json
"""

import argparse
import json
import sys
import time
from dataclasses import asdict, dataclass
from datetime import datetime
from typing import Dict, List, Optional

import numpy as np


@dataclass
class NoveltyScore:
    """æ–°é¢–åº¦è¯„åˆ†æ•°æ®ç»“æ„"""
    target: str
    novelty_score: float
    confidence: float
    breakdown: Dict[str, float]
    metadata: Dict
    interpretation: str


class PubMedSearcher:
    """PubMedæ–‡çŒ®æ£€ç´¢å™¨ (æ¨¡æ‹Ÿå®ç°)"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
    
    def search(self, query: str, years: int = 5) -> Dict:
        """
        æœç´¢PubMedæ–‡çŒ®
        
        å®é™…å®ç°åº”è¯¥è°ƒç”¨NCBI E-utilities API
        è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
        """
        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        current_year = datetime.now().year
        
        # åŸºäºé¶ç‚¹åç§°ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (å®é™…å®ç°ä¸­åº”è¯¥è°ƒç”¨çœŸå®API)
        np.random.seed(hash(query) % 2**32)
        
        total_papers = np.random.randint(100, 50000)
        recent_papers = int(total_papers * np.random.uniform(0.1, 0.5))
        clinical_trials = np.random.randint(0, min(200, total_papers // 100))
        
        # ç”Ÿæˆå¹´ä»½åˆ†å¸ƒ
        year_distribution = {
            str(year): np.random.randint(recent_papers // years // 2, recent_papers // years * 2)
            for year in range(current_year - years, current_year + 1)
        }
        
        return {
            "query": query,
            "total_count": total_papers,
            "recent_count": recent_papers,
            "clinical_trials": clinical_trials,
            "year_distribution": year_distribution,
            "search_year": current_year,
            "years_analyzed": years
        }


class NoveltyScorer:
    """é¶ç‚¹æ–°é¢–åº¦è¯„åˆ†å™¨"""
    
    def __init__(self):
        self.searcher = PubMedSearcher()
        
        # è¯„åˆ†æƒé‡é…ç½®
        self.weights = {
            "research_heat": 0.25,      # ç ”ç©¶çƒ­åº¦ 25%
            "uniqueness": 0.25,         # ç‹¬ç‰¹æ€§ 25%
            "research_depth": 0.20,     # ç ”ç©¶æ·±åº¦ 20%
            "collaboration": 0.15,      # åˆä½œç½‘ç»œ 15%
            "trend": 0.15               # æ—¶é—´è¶‹åŠ¿ 15%
        }
    
    def _score_research_heat(self, data: Dict) -> float:
        """
        è¯„åˆ†: ç ”ç©¶çƒ­åº¦ (0-25åˆ†)
        åŸºäºè¿‘å¹´æ–‡çŒ®æ•°é‡å’Œå¼•ç”¨é‡
        """
        total = data.get("total_count", 0)
        recent = data.get("recent_count", 0)
        
        # æ–‡çŒ®æ•°é‡è¯„åˆ† (0-15åˆ†)
        if total < 500:
            quantity_score = 12 + (total / 500) * 3  # ç¨€ç¼º: é«˜åˆ†
        elif total < 5000:
            quantity_score = 8 + (5000 - total) / 4500 * 4
        elif total < 20000:
            quantity_score = 4 + (20000 - total) / 15000 * 4
        else:
            quantity_score = max(0, 4 - (total - 20000) / 50000)
        
        # è¿‘æœŸæ´»è·ƒåº¦è¯„åˆ† (0-10åˆ†)
        recent_ratio = recent / total if total > 0 else 0
        recency_score = min(10, recent_ratio * 20)
        
        return min(25, quantity_score + recency_score)
    
    def _score_uniqueness(self, data: Dict, target: str) -> float:
        """
        è¯„åˆ†: ç‹¬ç‰¹æ€§ (0-25åˆ†)
        ä¸å·²çŸ¥çƒ­é—¨é¶ç‚¹çš„åŒºåˆ†åº¦
        """
        total = data.get("total_count", 0)
        
        # çƒ­é—¨é¶ç‚¹åˆ—è¡¨ (ç¤ºä¾‹)
        hot_targets = ["p53", "KRAS", "EGFR", "HER2", "PD-L1", "PD-1", "VEGF"]
        
        # å¦‚æœæœ¬èº«å°±æ˜¯çƒ­é—¨é¶ç‚¹ï¼Œç‹¬ç‰¹æ€§è¾ƒä½
        if target.upper() in [t.upper() for t in hot_targets]:
            base_score = 5
        else:
            # åŸºäºæ–‡çŒ®æ•°é‡çš„ç‹¬ç‰¹æ€§
            if total < 1000:
                base_score = 20 + min(5, (1000 - total) / 200)
            elif total < 5000:
                base_score = 15 + (5000 - total) / 4000 * 5
            elif total < 15000:
                base_score = 8 + (15000 - total) / 10000 * 7
            else:
                base_score = max(0, 8 - (total - 15000) / 20000 * 8)
        
        return min(25, base_score)
    
    def _score_research_depth(self, data: Dict) -> float:
        """
        è¯„åˆ†: ç ”ç©¶æ·±åº¦ (0-20åˆ†)
        ä¸´åºŠå‰/ä¸´åºŠç ”ç©¶çš„è¿›å±•ç¨‹åº¦
        """
        clinical_trials = data.get("clinical_trials", 0)
        total = data.get("total_count", 0)
        
        # ä¸´åºŠè¯•éªŒæ•°é‡è¯„åˆ†
        if clinical_trials == 0:
            clinical_score = 8  # æ—©æœŸé¶ç‚¹ï¼Œæ½œåŠ›æœªçŸ¥
        elif clinical_trials < 10:
            clinical_score = 12 + clinical_trials * 0.5
        elif clinical_trials < 50:
            clinical_score = 16 + (clinical_trials - 10) * 0.1
        else:
            clinical_score = max(10, 20 - (clinical_trials - 50) * 0.05)
        
        # åŸºç¡€ç ”ç©¶æ·±åº¦ (åŸºäºæ€»æ–‡çŒ®æ•°)
        if total < 1000:
            basic_score = 2
        elif total < 5000:
            basic_score = 3
        else:
            basic_score = 4
        
        return min(20, clinical_score + basic_score)
    
    def _score_collaboration(self, data: Dict) -> float:
        """
        è¯„åˆ†: åˆä½œç½‘ç»œ (0-15åˆ†)
        ç ”ç©¶æœºæ„/å›¢é˜Ÿçš„åˆ†å¸ƒå¤šæ ·æ€§
        """
        total = data.get("total_count", 0)
        
        # åŸºäºæ–‡çŒ®æ•°é‡çš„åˆä½œå¤šæ ·æ€§ä¼°è®¡
        if total < 100:
            diversity_score = 5
        elif total < 1000:
            diversity_score = 8 + (total - 100) / 900 * 4
        elif total < 5000:
            diversity_score = 12 + (total - 1000) / 4000 * 3
        else:
            diversity_score = 15
        
        return min(15, diversity_score)
    
    def _score_trend(self, data: Dict) -> float:
        """
        è¯„åˆ†: æ—¶é—´è¶‹åŠ¿ (0-15åˆ†)
        è¿‘å¹´ç ”ç©¶å¢é•¿è¶‹åŠ¿
        """
        year_dist = data.get("year_distribution", {})
        
        if not year_dist or len(year_dist) < 2:
            return 7.5  # ä¸­æ€§è¯„åˆ†
        
        # è®¡ç®—å¢é•¿è¶‹åŠ¿
        years = sorted(year_dist.keys())
        values = [year_dist[y] for y in years]
        
        if len(values) >= 2:
            # ç®€å•çº¿æ€§è¶‹åŠ¿
            early_avg = np.mean(values[:len(values)//2])
            recent_avg = np.mean(values[len(values)//2:])
            
            if early_avg > 0:
                growth_rate = (recent_avg - early_avg) / early_avg
            else:
                growth_rate = 0
            
            # è½¬æ¢ä¸º0-15åˆ†
            if growth_rate > 1.0:  # å¢é•¿è¶…è¿‡100%
                trend_score = 15
            elif growth_rate > 0.5:
                trend_score = 12 + (growth_rate - 0.5) * 6
            elif growth_rate > 0.2:
                trend_score = 9 + (growth_rate - 0.2) * 10
            elif growth_rate > 0:
                trend_score = 6 + growth_rate * 15
            elif growth_rate > -0.2:
                trend_score = max(0, 6 + growth_rate * 30)
            else:
                trend_score = max(0, 3 + (growth_rate + 0.2) * 15)
        else:
            trend_score = 7.5
        
        return min(15, max(0, trend_score))
    
    def calculate_confidence(self, data: Dict) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦ (0-1)"""
        total = data.get("total_count", 0)
        
        # æ–‡çŒ®è¶Šå¤šï¼Œç½®ä¿¡åº¦è¶Šé«˜
        if total < 50:
            return 0.4
        elif total < 200:
            return 0.6
        elif total < 1000:
            return 0.75
        elif total < 5000:
            return 0.85
        else:
            return 0.90
    
    def generate_interpretation(self, score: float, data: Dict) -> str:
        """ç”Ÿæˆè¯„åˆ†è§£è¯»"""
        total = data.get("total_count", 0)
        clinical = data.get("clinical_trials", 0)
        
        if score >= 80:
            level = "æé«˜æ–°é¢–åº¦"
            desc = "è¯¥é¶ç‚¹ç ”ç©¶è¾ƒå°‘ä½†å…·æœ‰ç‹¬ç‰¹ä»·å€¼ï¼Œæ˜¯æå…·æ½œåŠ›çš„åˆ›æ–°æ–¹å‘ã€‚"
        elif score >= 65:
            level = "é«˜æ–°é¢–åº¦"
            desc = "è¯¥é¶ç‚¹å…·æœ‰ä¸€å®šç ”ç©¶åŸºç¡€ä½†ä»æœ‰è¾ƒå¤§æ¢ç´¢ç©ºé—´ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨ã€‚"
        elif score >= 50:
            level = "ä¸­ç­‰æ–°é¢–åº¦"
            desc = "è¯¥é¶ç‚¹ç ”ç©¶çƒ­åº¦é€‚ä¸­ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°å…¶å·®å¼‚åŒ–ä¼˜åŠ¿ã€‚"
        elif score >= 35:
            level = "è¾ƒä½æ–°é¢–åº¦"
            desc = "è¯¥é¶ç‚¹å·²æœ‰è¾ƒå¤šç ”ç©¶ï¼Œç«äº‰æ¿€çƒˆï¼Œéœ€è¦å¯»æ‰¾ç»†åˆ†é¢†åŸŸçªç ´å£ã€‚"
        else:
            level = "ä½æ–°é¢–åº¦"
            desc = "è¯¥é¶ç‚¹æ˜¯æˆç†Ÿç ”ç©¶æ–¹å‘ï¼Œåˆ›æ–°ç©ºé—´æœ‰é™ï¼Œéœ€è°¨æ…è¯„ä¼°æŠ•å…¥äº§å‡ºæ¯”ã€‚"
        
        details = f"æ–‡çŒ®æ€»é‡: {total}, ä¸´åºŠè¯•éªŒ: {clinical}é¡¹ã€‚"
        
        return f"ã€{level}ã€‘{desc} {details}"
    
    def score(self, target: str, years: int = 5) -> NoveltyScore:
        """
        è®¡ç®—é¶ç‚¹æ–°é¢–åº¦è¯„åˆ†
        
        Args:
            target: é¶ç‚¹åç§°æˆ–åŸºå› ç¬¦å·
            years: åˆ†æå¹´ä»½èŒƒå›´
            
        Returns:
            NoveltyScoreå¯¹è±¡
        """
        # æ£€ç´¢æ–‡çŒ®æ•°æ®
        search_result = self.searcher.search(target, years)
        
        # è®¡ç®—å„ç»´åº¦å¾—åˆ†
        breakdown = {
            "research_heat": self._score_research_heat(search_result),
            "uniqueness": self._score_uniqueness(search_result, target),
            "research_depth": self._score_research_depth(search_result),
            "collaboration": self._score_collaboration(search_result),
            "trend": self._score_trend(search_result)
        }
        
        # è®¡ç®—æ€»åˆ† (åŠ æƒå¹³å‡)
        total_score = sum(
            breakdown[key] * self.weights[key] 
            for key in breakdown
        )
        
        # å½’ä¸€åŒ–åˆ°0-100
        novelty_score = round(total_score * 100 / 25, 1)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self.calculate_confidence(search_result)
        
        # æ„å»ºå…ƒæ•°æ®
        metadata = {
            "total_papers": search_result["total_count"],
            "recent_papers": search_result["recent_count"],
            "clinical_trials": search_result["clinical_trials"],
            "analysis_date": datetime.now().strftime("%Y-%m-%d"),
            "years_analyzed": years
        }
        
        # ç”Ÿæˆè§£è¯»
        interpretation = self.generate_interpretation(novelty_score, search_result)
        
        return NoveltyScore(
            target=target,
            novelty_score=novelty_score,
            confidence=round(confidence, 2),
            breakdown={k: round(v * 100 / 25, 1) for k, v in breakdown.items()},
            metadata=metadata,
            interpretation=interpretation
        )


def format_text_output(result: NoveltyScore) -> str:
    """æ ¼å¼åŒ–æ–‡æœ¬è¾“å‡º"""
    lines = [
        "=" * 60,
        f"ğŸ¯ é¶ç‚¹æ–°é¢–åº¦è¯„åˆ†æŠ¥å‘Š: {result.target}",
        "=" * 60,
        "",
        f"ğŸ“Š ç»¼åˆè¯„åˆ†: {result.novelty_score}/100",
        f"ğŸ”’ ç½®ä¿¡åº¦: {result.confidence * 100:.0f}%",
        "",
        "ğŸ“ˆ ç»´åº¦å¾—åˆ†:",
        f"  â€¢ ç ”ç©¶çƒ­åº¦:   {result.breakdown['research_heat']:.1f}/100",
        f"  â€¢ ç‹¬ç‰¹æ€§:     {result.breakdown['uniqueness']:.1f}/100",
        f"  â€¢ ç ”ç©¶æ·±åº¦:   {result.breakdown['research_depth']:.1f}/100",
        f"  â€¢ åˆä½œç½‘ç»œ:   {result.breakdown['collaboration']:.1f}/100",
        f"  â€¢ æ—¶é—´è¶‹åŠ¿:   {result.breakdown['trend']:.1f}/100",
        "",
        "ğŸ“‹ ç»Ÿè®¡ä¿¡æ¯:",
        f"  â€¢ æ–‡çŒ®æ€»é‡: {result.metadata['total_papers']:,}",
        f"  â€¢ è¿‘å¹´æ–‡çŒ®: {result.metadata['recent_papers']:,}",
        f"  â€¢ ä¸´åºŠè¯•éªŒ: {result.metadata['clinical_trials']}é¡¹",
        f"  â€¢ åˆ†ææ—¥æœŸ: {result.metadata['analysis_date']}",
        "",
        f"ğŸ’¡ è§£è¯»: {result.interpretation}",
        "",
        "=" * 60
    ]
    return "\n".join(lines)


def format_csv_output(result: NoveltyScore) -> str:
    """æ ¼å¼åŒ–CSVè¾“å‡º"""
    headers = [
        "target", "novelty_score", "confidence",
        "research_heat", "uniqueness", "research_depth",
        "collaboration", "trend", "total_papers",
        "recent_papers", "clinical_trials", "interpretation"
    ]
    
    values = [
        result.target,
        result.novelty_score,
        result.confidence,
        result.breakdown['research_heat'],
        result.breakdown['uniqueness'],
        result.breakdown['research_depth'],
        result.breakdown['collaboration'],
        result.breakdown['trend'],
        result.metadata['total_papers'],
        result.metadata['recent_papers'],
        result.metadata['clinical_trials'],
        f'"{result.interpretation}"'
    ]
    
    return ",".join(map(str, values))


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="é¶ç‚¹æ–°é¢–åº¦è¯„åˆ†å·¥å…· - åŸºäºæ–‡çŒ®æŒ–æ˜",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python main.py --target "PD-L1"
  python main.py --target "BRCA1" --years 10 --format json
  python main.py --target "EGFR" --output report.json
        """
    )
    
    parser.add_argument(
        "--target", "-t",
        required=True,
        help="ç›®æ ‡é¶ç‚¹åç§°æˆ–åŸºå› ç¬¦å· (å¦‚: PD-L1, BRCA1)"
    )
    parser.add_argument(
        "--db", "-d",
        choices=["pubmed", "pmc", "all"],
        default="pubmed",
        help="æ•°æ®æº (é»˜è®¤: pubmed)"
    )
    parser.add_argument(
        "--years", "-y",
        type=int,
        default=5,
        help="åˆ†æå¹´ä»½èŒƒå›´ (é»˜è®¤: 5)"
    )
    parser.add_argument(
        "--output", "-o",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: stdout)"
    )
    parser.add_argument(
        "--format", "-f",
        choices=["text", "json", "csv"],
        default="text",
        help="è¾“å‡ºæ ¼å¼ (é»˜è®¤: text)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="è¯¦ç»†è¾“å‡ºæ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    # æ‰§è¡Œè¯„åˆ†
    try:
        scorer = NoveltyScorer()
        result = scorer.score(args.target, args.years)
        
        # æ ¼å¼åŒ–è¾“å‡º
        if args.format == "json":
            output = json.dumps(asdict(result), ensure_ascii=False, indent=2)
        elif args.format == "csv":
            output = format_csv_output(result)
        else:
            output = format_text_output(result)
        
        # è¾“å‡ºç»“æœ
        if args.output:
            with open(args.output, "w", encoding="utf-8") as f:
                f.write(output)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {args.output}")
        else:
            print(output)
        
        # è¯¦ç»†æ¨¡å¼
        if args.verbose and args.format == "text":
            print(f"\nğŸ“Š åŸå§‹æ•°æ®: {json.dumps(result.metadata, ensure_ascii=False)}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
