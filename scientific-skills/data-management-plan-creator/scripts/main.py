#!/usr/bin/env python3
"""
Data Management and Sharing Plan (DMSP) Creator
Generates NIH 2023-compliant DMSP drafts following FAIR principles.

Author: OpenClaw
Version: 1.0.0
"""

import argparse
import json
import os
import re
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import List, Optional


@dataclass
class DMSPData:
    """Data class for DMSP inputs."""
    project_title: str
    pi_name: str
    institution: str
    data_types: List[str]
    estimated_size_gb: Optional[float] = None
    repositories: List[str] = field(default_factory=list)
    sharing_timeline: str = "No later than the end of the award period"
    access_restrictions: str = ""
    format_standards: List[str] = field(default_factory=list)
    tools_software: List[str] = field(default_factory=list)
    metadata_standards: List[str] = field(default_factory=list)
    oversight_plan: str = ""
    contact_email: str = ""


class DMSPCreator:
    """Creates NIH 2023-compliant Data Management and Sharing Plans."""
    
    # NIH-required section headers
    SECTIONS = [
        "1. Data Type",
        "2. Related Tools, Software and/or Code", 
        "3. Standards",
        "4. Data Preservation, Access, and Associated Timelines",
        "5. Access, Distribution, or Reuse Considerations",
        "6. Oversight of Data Management and Sharing"
    ]
    
    # FAIR-aligned repository recommendations
    REPOSITORY_GUIDE = {
        "genomic": ["NCBI GEO", "dbGaP", "ENA", "DDBJ", "NCBI SRA"],
        "sequencing": ["NCBI SRA", "ENA", "DDBJ"],
        "imaging": ["Figshare", "Zenodo", "IDR", "BioImage Archive"],
        "clinical": ["dbGaP", "ClinicalTrials.gov", "Vivli"],
        "proteomic": ["PRIDE", "MassIVE", "iProX"],
        "metabolomic": ["MetaboLights", "Metabolomics Workbench"],
        "software": ["GitHub", "Zenodo", "Figshare"],
        "general": ["Dryad", "Zenodo", "Figshare", "Mendeley Data"]
    }
    
    # Standard metadata vocabularies
    METADATA_STANDARDS = {
        "genomic": ["MIAME", "MINSEQE", "Darwin Core"],
        "imaging": ["OME-TIFF", "DICOM", "NIH Common Data Elements"],
        "clinical": ["CDISC", "FHIR", "OMOP CDM"],
        "proteomic": ["HUPO-PSI", "mzML", "mzIdentML"],
        "general": ["Dublin Core", "DataCite", "Schema.org"]
    }
    
    def __init__(self, data: DMSPData):
        self.data = data
        self.generated_content = ""
        self.timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def generate_plan(self) -> str:
        """Generate complete DMSP document."""
        sections = [
            self._generate_header(),
            self._generate_executive_summary(),
            self._generate_section_1_data_type(),
            self._generate_section_2_tools(),
            self._generate_section_3_standards(),
            self._generate_section_4_preservation(),
            self._generate_section_5_access(),
            self._generate_section_6_oversight(),
            self._generate_fair_alignment(),
            self._generate_references()
        ]
        
        self.generated_content = "\n\n".join(sections)
        return self.generated_content
    
    def _generate_header(self) -> str:
        """Generate document header with metadata."""
        return f"""# Data Management and Sharing Plan (DMSP)

**Project Title:** {self.data.project_title}
**Principal Investigator:** {self.data.pi_name}
**Institution:** {self.data.institution}
**Contact:** {self.data.contact_email or "[Add contact email]"}
**Plan Generated:** {self.timestamp}
**NIH Compliance Version:** 2023 Final Policy

---

## Document Information

This Data Management and Sharing Plan (DMSP) is prepared in accordance with the NIH Policy for Data Management and Sharing (Effective January 25, 2023). This plan addresses all required elements and aligns with FAIR principles (Findable, Accessible, Interoperable, Reusable).
"""
    
    def _generate_executive_summary(self) -> str:
        """Generate executive summary."""
        data_types_str = ", ".join(self.data.data_types)
        repos_str = ", ".join(self.data.repositories) if self.data.repositories else "[To be determined]"
        
        return f"""## Executive Summary

This DMSP outlines the management and sharing of scientific data generated by the research project "{self.data.project_title}". 

**Key Points:**
- **Data Types:** {data_types_str}
- **Target Repositories:** {repos_str}
- **Sharing Timeline:** {self.data.sharing_timeline}
- **Estimated Data Volume:** {self.data.estimated_size_gb or "[Not specified]"} GB
- **FAIR Alignment:** This plan ensures data will be Findable, Accessible, Interoperable, and Reusable.

The Principal Investigator ({self.data.pi_name}) will oversee implementation of this plan, ensuring compliance with NIH policies and institutional requirements.
"""
    
    def _generate_section_1_data_type(self) -> str:
        """Generate Section 1: Data Type."""
        data_types_bullets = "\n".join([f"  - {dt.strip()}" for dt in self.data.data_types])
        
        size_desc = f"""
**Estimated Data Volume:**
The total estimated data volume is approximately {self.data.estimated_size_gb} GB. Data growth will be monitored throughout the project, and this estimate will be updated as needed.""" if self.data.estimated_size_gb else ""
        
        return f"""### {self.SECTIONS[0]}

**Scientific Data to be Generated:**
{data_types_bullets}

The project will generate the following types of scientific data:

1. **Raw Data:** Original unprocessed data files generated by instruments and data collection procedures.
2. **Processed Data:** Data that has undergone quality control, normalization, or other analytical transformations.
3. **Metadata:** Descriptive information about the data, including collection methods, experimental parameters, and data dictionaries.
4. **Derived Data:** Results of analyses, including statistical outputs, visualizations, and summary tables.
{size_desc}

**Data That Will NOT be Shared:**
The following data types are excluded from sharing:
- Data that cannot be de-identified while preserving scientific utility
- Data protected by existing privacy laws and regulations
- Proprietary data governed by third-party agreements (with documented justification)

**Justification for Any Limitations:**
Any limitations on data sharing will be documented with specific justification as required by NIH policy, including reference to applicable laws, regulations, or institutional policies.
"""
    
    def _generate_section_2_tools(self) -> str:
        """Generate Section 2: Related Tools, Software and/or Code."""
        tools = self.data.tools_software or [
            "Standard data analysis software (R, Python, MATLAB)",
            "Version control systems (Git/GitHub)",
            "Data visualization tools"
        ]
        tools_bullets = "\n".join([f"  - {tool}" for tool in tools])
        
        return f"""### {self.SECTIONS[1]}

**Tools and Software for Data Access and Analysis:**

{tools_bullets}

**Specialized Software Requirements:**
- Data will be stored in formats compatible with widely-used, open-source software
- Proprietary software requirements will be documented with version information
- Custom code developed for data processing will be made available through public repositories (e.g., GitHub, Zenodo)

**Hardware Requirements:**
- Standard computing infrastructure for data analysis
- Adequate storage capacity for backup and archiving
- Network infrastructure supporting data transfer to repositories

**Accessibility:**
- All software/tools required to access the data will be documented
- Where possible, open-source alternatives will be prioritized
- Licensing requirements for proprietary software will be clearly stated
"""
    
    def _generate_section_3_standards(self) -> str:
        """Generate Section 3: Standards."""
        # Auto-suggest standards based on data types
        suggested_standards = set()
        for dt in self.data.data_types:
            dt_lower = dt.lower()
            for key, standards in self.METADATA_STANDARDS.items():
                if key in dt_lower:
                    suggested_standards.update(standards)
        
        if self.data.metadata_standards:
            standards_list = self.data.metadata_standards
        else:
            standards_list = list(suggested_standards) if suggested_standards else ["Dublin Core", "DataCite"]
        
        standards_bullets = "\n".join([f"  - {std}" for std in standards_list])
        
        formats = self.data.format_standards or [
            "Open, non-proprietary formats where available",
            "Community-standard formats for specific data types",
            "Documentation of any proprietary formats used"
        ]
        formats_bullets = "\n".join([f"  - {fmt}" for fmt in formats])
        
        return f"""### {self.SECTIONS[2]}

**Metadata Standards:**

The following metadata standards will be applied to ensure FAIR compliance:

{standards_bullets}

**Metadata Content:**
- Descriptive metadata (title, abstract, keywords, investigators)
- Structural metadata (data dictionaries, codebooks, file formats)
- Administrative metadata (creation date, version, access permissions)
- Provenance metadata (data lineage, processing steps, quality control)

**Data Format Standards:**

{formats_bullets}

**Standard Vocabularies and Ontologies:**
- Domain-specific ontologies will be used for semantic annotation
- Controlled vocabularies will be applied to facilitate search and integration
- Mappings between vocabularies will be documented where applicable

**Quality Control Standards:**
- Data validation procedures will be documented
- Quality metrics will be included with shared data
- Error tracking and correction procedures will be maintained
"""
    
    def _generate_section_4_preservation(self) -> str:
        """Generate Section 4: Data Preservation, Access, and Associated Timelines."""
        repos = self.data.repositories or ["[To be determined based on data type requirements]"]
        repos_bullets = "\n".join([f"  - {repo}" for repo in repos])
        
        # Suggest repositories based on data types
        suggested_repos = set()
        for dt in self.data.data_types:
            dt_lower = dt.lower()
            for key, repo_list in self.REPOSITORY_GUIDE.items():
                if key in dt_lower:
                    suggested_repos.update(repo_list)
        
        suggested_text = ""
        if suggested_repos:
            suggested_text = f"""
**NIH-Approved Repository Suggestions:**
Based on your data types, consider the following NIH-approved repositories:
{chr(10).join([f"  - {r}" for r in sorted(suggested_repos)[:5]])}
"""
        
        return f"""### {self.SECTIONS[3]}

**Selected Data Repositories:**

{repos_bullets}
{suggested_text}

**Repository Selection Criteria:**
Repositories were selected based on the following criteria:
- NIH approval and domain relevance
- Long-term sustainability and funding stability
- Support for FAIR data principles
- Appropriate access controls for sensitive data
- Rich metadata capabilities

**Preservation Timeline:**
- **Data Collection Period:** Data will be managed and backed up throughout the active research period
- **Sharing Deadline:** {self.data.sharing_timeline}
- **Retention Period:** Data will be preserved for a minimum period consistent with NIH and institutional requirements (typically 3-7 years post-award)

**Persistent Identifiers:**
- Digital Object Identifiers (DOIs) will be obtained for shared datasets
- Accession numbers from repositories will be documented
- Persistent URLs will be maintained for all data locations

**Data Transfer Procedures:**
- Secure data transfer protocols will be used
- Data integrity verification (checksums) will be performed
- Transfer logs will be maintained
"""
    
    def _generate_section_5_access(self) -> str:
        """Generate Section 5: Access, Distribution, or Reuse Considerations."""
        restrictions = self.data.access_restrictions or """
**Access Level Determination:**
- Open access for non-sensitive, de-identified data
- Controlled access for data requiring additional protections
- Embargo periods may apply (with documented justification)
"""
        
        return f"""### {self.SECTIONS[4]}

**Access Control and Distribution:**

{restrictions}

**Informed Consent:**
- Informed consent documents address data sharing
- Participants are informed about how their data will be used and shared
- Consent documentation is maintained securely

**Privacy and Confidentiality:**
- Data will be de-identified according to HIPAA Safe Harbor or Expert Determination methods
- Re-identification risk assessments will be conducted where applicable
- Additional safeguards applied to sensitive data elements

**Intellectual Property and Licensing:**
- Data will be shared under open licenses (e.g., CC0, CC-BY) where appropriate
- Patent or commercial confidentiality considerations will be documented
- Contributor rights and attribution requirements will be specified

**Ethical Considerations:**
- IRB approval includes data sharing plans
- Any ethical limitations on data sharing are documented
- International data transfer requirements (e.g., GDPR) are addressed

**Reuse Conditions:**
- Users must cite the original publication and dataset
- Data use agreements may be required for controlled-access data
- Commercial use restrictions will be clearly stated if applicable
"""
    
    def _generate_section_6_oversight(self) -> str:
        """Generate Section 6: Oversight of Data Management and Sharing."""
        oversight = self.data.oversight_plan or f"""
The Principal Investigator ({self.data.pi_name}) will have primary responsibility for oversight of data management and sharing activities.

**Roles and Responsibilities:**
- **Principal Investigator:** Overall compliance, final approval of data sharing decisions
- **Data Manager:** Day-to-day data management, quality control, repository submissions
- **IT Support:** Infrastructure maintenance, security, backup procedures
"""
        
        return f"""### {self.SECTIONS[5]}

{oversight}

**Compliance Monitoring:**
- Regular reviews of data management practices will be conducted
- Compliance with this DMSP will be verified at key project milestones
- Updates to the plan will be made as needed with appropriate approvals

**Plan Updates:**
- This DMSP is a living document and may be updated as the project evolves
- Significant changes will be documented with version control
- NIH will be notified of substantial changes as required

**Training:**
- Research personnel will receive training on data management best practices
- FAIR data principles will be incorporated into team training
- Security and privacy training will be provided as required

**Budget Considerations:**
- Costs associated with data management and sharing are included in the grant budget
- Repository fees, storage costs, and personnel time have been accounted for
"""
    
    def _generate_fair_alignment(self) -> str:
        """Generate FAIR principles alignment section."""
        return """## FAIR Principles Alignment

This DMSP ensures compliance with the FAIR principles for scientific data management:

### Findable
- **F1:** Data is assigned a globally unique and persistent identifier (DOI)
- **F2:** Data is described with rich metadata using standardized vocabularies
- **F3:** Metadata clearly and explicitly includes the identifier of the data it describes
- **F4:** Data is registered or indexed in a searchable resource (repository)

### Accessible
- **A1:** Data is retrievable by its identifier using a standardized communications protocol
- **A1.1:** The protocol is open, free, and universally implementable
- **A1.2:** The protocol allows for an authentication and authorization procedure
- **A2:** Metadata is accessible, even when the data is no longer available

### Interoperable
- **I1:** Data uses a formal, accessible, shared, and broadly applicable language for knowledge representation
- **I2:** Data uses vocabularies that follow FAIR principles
- **I3:** Data includes qualified references to other data

### Reusable
- **R1:** Data is described with a plurality of accurate and relevant attributes
- **R1.1:** Data is released with a clear and accessible data usage license
- **R1.2:** Data is associated with detailed provenance information
- **R1.3:** Data meets domain-relevant community standards
"""
    
    def _generate_references(self) -> str:
        """Generate references section."""
        return """## References and Resources

### NIH Resources
- [NIH Data Management and Sharing Policy](https://sharing.nih.gov/data-management-and-sharing-policy)
- [NIH Plan for Increasing Access to Scientific Publications and Digital Scientific Data](https://grants.nih.gov/grants/guide/notice-files/NOT-OD-15-102.html)
- [Selecting a Data Repository](https://sharing.nih.gov/data-management-and-sharing-policy/sharing-scientific-data/selecting-a-data-repository)

### FAIR Resources
- [FAIR Principles](https://www.go-fair.org/fair-principles/)
- [FAIR Data Maturity Model](https://www.rd-alliance.org/group/fair-data-maturity-model-wg/outcomes/fair-data-maturity-model-specification-and-guidelines-0)

### Repository Resources
- [Registry of Research Data Repositories (re3data)](https://www.re3data.org/)
- [NIH-supported Domain-Specific Repositories](https://sharing.nih.gov/data-management-and-sharing-policy/sharing-scientific-data/nih-domain-specific-repository-selection-guide)

---

*This Data Management and Sharing Plan was generated using the DMP Creator Skill (ID: 102).*
*Please review and customize this draft before submission to NIH.*
"""
    
    def save_to_file(self, filepath: Optional[str] = None) -> str:
        """Save generated plan to file."""
        if not filepath:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = f"dmsp_{timestamp}.md"
        
        Path(filepath).write_text(self.generated_content, encoding="utf-8")
        return filepath


def interactive_mode() -> DMSPData:
    """Run interactive mode to collect DMSP information."""
    print("=" * 60)
    print("NIH Data Management and Sharing Plan (DMSP) Creator")
    print("=" * 60)
    print("\nPlease provide the following information:\n")
    
    def get_input(prompt: str, required: bool = True) -> str:
        while True:
            value = input(f"{prompt}: ").strip()
            if value or not required:
                return value
            print("  (This field is required)")
    
    def get_list(prompt: str) -> List[str]:
        value = input(f"{prompt} (comma-separated): ").strip()
        return [v.strip() for v in value.split(",") if v.strip()]
    
    data = DMSPData(
        project_title=get_input("Project Title"),
        pi_name=get_input("Principal Investigator Name"),
        institution=get_input("Institution/Organization"),
        data_types=get_list("Data Types (e.g., genomic, imaging, clinical)"),
        estimated_size_gb=None,
        repositories=get_list("Target Repositories"),
        sharing_timeline=input("Sharing Timeline (press Enter for default): ").strip() or "No later than the end of the award period",
        access_restrictions=get_input("Access Restrictions (if any)", required=False),
        contact_email=get_input("Contact Email", required=False)
    )
    
    # Optional numeric input
    size_input = input("Estimated Data Size (GB, optional): ").strip()
    if size_input:
        try:
            data.estimated_size_gb = float(size_input)
        except ValueError:
            print("  (Invalid number, skipping)")
    
    return data


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate NIH 2023-compliant Data Management and Sharing Plan (DMSP)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Interactive mode
  python main.py --interactive
  
  # Command line with required arguments
  python main.py \\
    --project-title "Cancer Genomics Study" \\
    --pi-name "Dr. Jane Smith" \\
    --institution "NCI" \\
    --data-types "genomic,clinical"
        """
    )
    
    parser.add_argument("--interactive", "-i", action="store_true", 
                        help="Run in interactive mode")
    parser.add_argument("--project-title", help="Research project title")
    parser.add_argument("--pi-name", help="Principal Investigator name")
    parser.add_argument("--institution", help="Research institution")
    parser.add_argument("--data-types", help="Comma-separated list of data types")
    parser.add_argument("--estimated-size", type=float, help="Estimated data size in GB")
    parser.add_argument("--repository", help="Comma-separated list of repositories")
    parser.add_argument("--sharing-timeline", 
                        default="No later than the end of the award period",
                        help="Data sharing timeline")
    parser.add_argument("--access-restrictions", help="Access restrictions if any")
    parser.add_argument("--contact-email", help="Contact email address")
    parser.add_argument("--output", "-o", help="Output file path")
    parser.add_argument("--json", "-j", action="store_true",
                        help="Output as JSON instead of Markdown")
    
    args = parser.parse_args()
    
    # Collect data
    if args.interactive:
        data = interactive_mode()
    else:
        # Validate required args
        required = ["project_title", "pi_name", "institution", "data_types"]
        missing = [f"--{r.replace('_', '-')}" for r in required 
                   if not getattr(args, r)]
        if missing:
            parser.error(f"Missing required arguments: {', '.join(missing)}")
        
        data = DMSPData(
            project_title=args.project_title,
            pi_name=args.pi_name,
            institution=args.institution,
            data_types=[t.strip() for t in args.data_types.split(",")],
            estimated_size_gb=args.estimated_size,
            repositories=[r.strip() for r in args.repository.split(",")] if args.repository else [],
            sharing_timeline=args.sharing_timeline,
            access_restrictions=args.access_restrictions or "",
            contact_email=args.contact_email or ""
        )
    
    # Generate plan
    creator = DMSPCreator(data)
    plan = creator.generate_plan()
    
    # Output
    if args.json:
        output = {
            "metadata": {
                "project_title": data.project_title,
                "pi_name": data.pi_name,
                "generated_at": creator.timestamp
            },
            "content": plan
        }
        print(json.dumps(output, indent=2))
    else:
        print(plan)
    
    # Save to file
    filepath = creator.save_to_file(args.output)
    print(f"\n[Saved to: {filepath}]", file=sys.stderr)


if __name__ == "__main__":
    main()
