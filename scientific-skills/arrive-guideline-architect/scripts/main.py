#!/usr/bin/env python3
"""
ARRIVE Guideline Architect
åŸºäº ARRIVE 2.0 æ ‡å‡†è®¾è®¡æ— å¯æŒ‘å‰”çš„åŠ¨ç‰©å®éªŒæ–¹æ¡ˆ

Usage:
    python main.py --interactive          # äº¤äº’å¼å®éªŒè®¾è®¡
    python main.py --input file.json      # ä»è¾“å…¥æ–‡ä»¶ç”Ÿæˆæ–¹æ¡ˆ
    python main.py --validate file.md     # éªŒè¯ç°æœ‰æ–¹æ¡ˆåˆè§„æ€§
    python main.py --checklist            # ç”Ÿæˆ ARRIVE æ£€æŸ¥æ¸…å•
"""

import argparse
import json
import sys
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any


class ARRIVEGuidelineArchitect:
    """ARRIVE 2.0 å®éªŒæ–¹æ¡ˆæ¶æ„å¸ˆ"""
    
    # ARRIVE 2.0 Essential 10 æ£€æŸ¥é¡¹
    ESSENTIAL_10 = {
        "1. Study Design": {
            "description": "For each experiment, provide brief details of study design including: the number of experimental and control groups; the number of animals per group; and a clear statement of whether the experiment was performed blinded.",
            "checkpoints": [
                "æ˜ç¡®å®éªŒç»„å’Œå¯¹ç…§ç»„æ•°é‡",
                "æ˜ç¡®æ¯ç»„åŠ¨ç‰©æ•°é‡",
                "è¯´æ˜æ˜¯å¦é‡‡ç”¨ç›²æ³•"
            ]
        },
        "2. Sample Size": {
            "description": "Provide details of sample size calculation, including: the effect size of interest; the estimate of variability; the power; and the significance level.",
            "checkpoints": [
                "æ•ˆåº”é‡ä¼°è®¡ (effect size)",
                "å˜å¼‚åº¦ä¼°è®¡ (variability)",
                "æ£€éªŒæ•ˆèƒ½ (power, é€šå¸¸â‰¥80%)",
                "æ˜¾è‘—æ€§æ°´å¹³ (significance level, é€šå¸¸Î±=0.05)"
            ]
        },
        "3. Inclusion/Exclusion Criteria": {
            "description": "Provide details of inclusion and exclusion criteria for experimental units, including handling of any data exclusions.",
            "checkpoints": [
                "æ˜ç¡®çš„çº³å…¥æ ‡å‡†",
                "æ˜ç¡®çš„æ’é™¤æ ‡å‡†",
                "æ•°æ®æ’é™¤çš„å¤„ç†æ–¹å¼"
            ]
        },
        "4. Randomisation": {
            "description": "Provide details of: the randomisation method used to allocate experimental units to groups; and the randomisation method used to determine the order of treatments and measurements.",
            "checkpoints": [
                "åˆ†ç»„éšæœºåŒ–æ–¹æ³•",
                "æ²»ç–—å’Œæµ‹é‡é¡ºåºçš„éšæœºåŒ–æ–¹æ³•",
                "éšæœºåŒ–å®æ–½ç»†èŠ‚"
            ]
        },
        "5. Blinding": {
            "description": "Describe who was aware of group allocation at the different stages of the experiment (during the allocation, the conduct of the experiment, the outcome assessment, and the data analysis).",
            "checkpoints": [
                "åˆ†ç»„åˆ†é…é˜¶æ®µï¼šè°çŸ¥æƒ…",
                "å®éªŒæ‰§è¡Œé˜¶æ®µï¼šè°çŸ¥æƒ…",
                "ç»“å±€è¯„ä¼°é˜¶æ®µï¼šè°çŸ¥æƒ…",
                "æ•°æ®åˆ†æé˜¶æ®µï¼šè°çŸ¥æƒ…"
            ]
        },
        "6. Outcome Measures": {
            "description": "Define all outcome measures assessed (primary and secondary), clearly distinguishing between measures assessed as part of the experimental protocol and measures assessed in exploratory analyses.",
            "checkpoints": [
                "ä¸»è¦ç»“å±€æŒ‡æ ‡å®šä¹‰",
                "æ¬¡è¦ç»“å±€æŒ‡æ ‡å®šä¹‰",
                "åŒºåˆ†é¢„è®¾åˆ†æä¸æ¢ç´¢æ€§åˆ†æ"
            ]
        },
        "7. Statistical Methods": {
            "description": "Describe in full how the data were analysed, including all statistical methods applied to the data; and whether assumptions of the statistical approaches were met.",
            "checkpoints": [
                "å®Œæ•´çš„ç»Ÿè®¡æ–¹æ³•æè¿°",
                "å‡è®¾æ£€éªŒæ¡ä»¶éªŒè¯",
                "å¤šé‡æ¯”è¾ƒæ ¡æ­£æ–¹æ³•"
            ]
        },
        "8. Experimental Animals": {
            "description": "Provide full details of the animals used, including: species and strain; sex; age or developmental stage; weight or mass; source (including supplier or breeding centre); and any relevant welfare and housing details.",
            "checkpoints": [
                "ç‰©ç§å’Œå“ç³»",
                "æ€§åˆ«",
                "å¹´é¾„æˆ–å‘è‚²é˜¶æ®µ",
                "ä½“é‡/è´¨é‡",
                "æ¥æºï¼ˆä¾›åº”å•†æˆ–ç¹æ®–ä¸­å¿ƒï¼‰",
                "é¥²å…»æ¡ä»¶å’Œç¦åˆ©"
            ]
        },
        "9. Experimental Procedures": {
            "description": "Provide full details of all procedures carried out on the animals, including: what was done, how it was done, and what was used.",
            "checkpoints": [
                "è¯¦ç»†çš„æ“ä½œæ­¥éª¤",
                "æ“ä½œæ–¹æ³•å’Œå·¥å…·",
                "éº»é†‰å’Œé•‡ç—›æ–¹æ³•",
                "æ ·æœ¬é‡‡é›†æ–¹æ³•"
            ]
        },
        "10. Results": {
            "description": "Report the results for each analysis carried out, with a measure of precision (e.g., standard error or confidence interval), and include the exact number of experimental units analysed in each group.",
            "checkpoints": [
                "æ¯ç»„çš„ç²¾ç¡®æ•°å€¼ (ç²¾ç¡®åˆ°ä¸ªä½)",
                "å˜å¼‚åº¦æŒ‡æ ‡ (SD/SEM/CI)",
                "ç»Ÿè®¡é‡å’ŒPå€¼",
                "æ•ˆåº”é‡åŠç½®ä¿¡åŒºé—´"
            ]
        }
    }
    
    # Recommended Set (æ¨èé¡¹ç›®)
    RECOMMENDED_SET = {
        "11. Ethical Approval": "æä¾›ä¼¦ç†å®¡æ‰¹ä¿¡æ¯ï¼ŒåŒ…æ‹¬æœºæ„ä¼¦ç†å§”å‘˜ä¼šåç§°å’Œæ‰¹å‡†ç¼–å·",
        "12. Housing and Husbandry": "è¯¦ç»†çš„é¥²å…»ç¯å¢ƒæ¡ä»¶ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ã€å…‰ç…§å‘¨æœŸã€é¥²å…»å¯†åº¦ç­‰ï¼‰",
        "13. Animal Care and Monitoring": "åŠ¨ç‰©æŠ¤ç†å’Œç›‘æµ‹é¢‘ç‡ï¼Œäººé“ç»ˆæœ«ç‚¹è®¾ç½®",
        "14. Adverse Events": "ä¸è‰¯äº‹ä»¶çš„å®šä¹‰ã€ç›‘æµ‹å’Œå¤„ç†",
        "15. Data Access": "æ•°æ®å…±äº«å’Œè·å–å£°æ˜",
        "16. Conflicts of Interest": "åˆ©ç›Šå†²çªå£°æ˜",
        "17. Funding": "èµ„é‡‘æ¥æºå£°æ˜",
        "18. Limitations": "ç ”ç©¶å±€é™æ€§è¯´æ˜"
    }
    
    # å¸¸è§åŠ¨ç‰©å®éªŒç±»å‹æ¨¡æ¿
    STUDY_TEMPLATES = {
        "efficacy": {
            "name": "è¯æ•ˆå­¦ç ”ç©¶ (Efficacy Study)",
            "description": "è¯„ä¼°è¯ç‰©æˆ–æ²»ç–—æ–¹æ¡ˆåœ¨åŠ¨ç‰©æ¨¡å‹ä¸­çš„ç–—æ•ˆ",
            "typical_groups": ["Shamç»„", "æ¨¡å‹å¯¹ç…§ç»„", "é˜³æ€§å¯¹ç…§ç»„", "ä½å‰‚é‡ç»„", "ä¸­å‰‚é‡ç»„", "é«˜å‰‚é‡ç»„"],
            "typical_endpoints": ["ç–¾ç—…æ´»åŠ¨åº¦è¯„åˆ†", "ç”Ÿç‰©æ ‡å¿—ç‰©", "ç»„ç»‡ç—…ç†å­¦è¯„åˆ†"]
        },
        "toxicology": {
            "name": "æ¯’ç†å­¦ç ”ç©¶ (Toxicology Study)",
            "description": "è¯„ä¼°åŒ–åˆç‰©çš„å®‰å…¨æ€§ç‰¹å¾",
            "typical_groups": ["æº¶åª’å¯¹ç…§ç»„", "ä½å‰‚é‡ç»„", "ä¸­å‰‚é‡ç»„", "é«˜å‰‚é‡ç»„"],
            "typical_endpoints": ["ä½“é‡", "è¡€æ¶²å­¦æŒ‡æ ‡", "ä¸´åºŠç”ŸåŒ–", "è„å™¨é‡é‡", "ç»„ç»‡ç—…ç†å­¦"]
        },
        "pharmacokinetics": {
            "name": "è¯ä»£åŠ¨åŠ›å­¦ç ”ç©¶ (PK Study)",
            "description": "è¯„ä¼°è¯ç‰©åœ¨ä½“å†…çš„å¸æ”¶ã€åˆ†å¸ƒã€ä»£è°¢ã€æ’æ³„",
            "typical_groups": ["é™è„‰ç»™è¯ç»„", "å£æœç»™è¯ç»„"],
            "typical_endpoints": ["Cmax", "Tmax", "AUC", "åŠè¡°æœŸ", "æ¸…é™¤ç‡"]
        },
        "behavioral": {
            "name": "è¡Œä¸ºå­¦ç ”ç©¶ (Behavioral Study)",
            "description": "è¯„ä¼°åŠ¨ç‰©è¡Œä¸ºå˜åŒ–",
            "typical_groups": ["å¯¹ç…§ç»„", "æ¨¡å‹ç»„", "æ²»ç–—ç»„"],
            "typical_endpoints": ["è¿åŠ¨èƒ½åŠ›", "å­¦ä¹ è®°å¿†", "ç„¦è™‘æ ·è¡Œä¸º", "æŠ‘éƒæ ·è¡Œä¸º"]
        }
    }
    
    def __init__(self):
        self.protocol_data = {}
    
    def interactive_design(self) -> Dict[str, Any]:
        """äº¤äº’å¼å®éªŒè®¾è®¡å‘å¯¼"""
        print("=" * 70)
        print("ğŸ§¬ ARRIVE Guideline Architect - äº¤äº’å¼åŠ¨ç‰©å®éªŒè®¾è®¡å‘å¯¼")
        print("=" * 70)
        print("\næœ¬å‘å¯¼å°†å¸®åŠ©æ‚¨è®¾è®¡ç¬¦åˆ ARRIVE 2.0 æ ‡å‡†çš„åŠ¨ç‰©å®éªŒæ–¹æ¡ˆã€‚\n")
        
        data = {}
        
        # åŸºæœ¬ä¿¡æ¯
        print("ã€ç¬¬ä¸€æ­¥ã€‘åŸºæœ¬ä¿¡æ¯")
        print("-" * 40)
        data['title'] = input("ç ”ç©¶æ ‡é¢˜: ").strip()
        
        print("\nå®éªŒç±»å‹é€‰æ‹©:")
        for key, template in self.STUDY_TEMPLATES.items():
            print(f"  [{key}] {template['name']}: {template['description']}")
        
        study_type = input("\nè¯·é€‰æ‹©å®éªŒç±»å‹ (é»˜è®¤: efficacy): ").strip() or "efficacy"
        data['study_type'] = study_type
        
        # åŠ¨ç‰©ä¿¡æ¯
        print("\nã€ç¬¬äºŒæ­¥ã€‘å®éªŒåŠ¨ç‰©ä¿¡æ¯ (Item 8)")
        print("-" * 40)
        data['species'] = input("ç‰©ç§ (å¦‚: Mus musculus): ").strip() or "Mus musculus"
        data['strain'] = input("å“ç³» (å¦‚: C57BL/6J): ").strip()
        data['sex'] = input("æ€§åˆ« (Male/Female/Both): ").strip() or "Male"
        data['age'] = input("å¹´é¾„/å‘¨é¾„ (å¦‚: 8-10å‘¨): ").strip() or "8-10å‘¨"
        data['weight_range'] = input("ä½“é‡èŒƒå›´ (å¦‚: 20-25g): ").strip() or "20-25g"
        data['source'] = input("åŠ¨ç‰©æ¥æº (ä¾›åº”å•†æˆ–ç¹æ®–ä¸­å¿ƒ): ").strip() or "SPFçº§åŠ¨ç‰©ä¸­å¿ƒ"
        
        # å®éªŒè®¾è®¡
        print("\nã€ç¬¬ä¸‰æ­¥ã€‘å®éªŒè®¾è®¡ (Items 1, 2)")
        print("-" * 40)
        
        print("å®éªŒç»„åˆ«è®¾ç½®:")
        groups = []
        group_count = int(input("å®éªŒç»„æ•°é‡ (åŒ…å«å¯¹ç…§ç»„): ").strip() or "3")
        
        for i in range(group_count):
            group_name = input(f"  ç»„ {i+1} åç§°: ").strip()
            treatment = input(f"  ç»„ {i+1} å¤„ç†æ–¹å¼: ").strip()
            groups.append({"name": group_name, "treatment": treatment})
        data['groups'] = groups
        
        # æ ·æœ¬é‡
        sample_size = input(f"\næ¯ç»„åŠ¨ç‰©æ•°é‡ (é»˜è®¤: 10): ").strip() or "10"
        data['sample_size_per_group'] = int(sample_size)
        data['total_animals'] = data['sample_size_per_group'] * len(groups)
        
        print("\næ ·æœ¬é‡è®¡ç®—ä¾æ®:")
        data['effect_size'] = input("  é¢„æœŸæ•ˆåº”é‡ (å¦‚: 0.8): ").strip() or "0.8"
        data['power'] = input("  æ£€éªŒæ•ˆèƒ½ (é»˜è®¤: 0.80): ").strip() or "0.80"
        data['alpha'] = input("  æ˜¾è‘—æ€§æ°´å¹³ Î± (é»˜è®¤: 0.05): ").strip() or "0.05"
        
        # éšæœºåŒ–å’Œç›²æ³•
        print("\nã€ç¬¬å››æ­¥ã€‘éšæœºåŒ–ä¸ç›²æ³• (Items 4, 5)")
        print("-" * 40)
        data['randomization_method'] = input(
            "éšæœºåŒ–æ–¹æ³• (å¦‚: è®¡ç®—æœºéšæœºæ•°è¡¨/éšæœºæ•°å­—ç”Ÿæˆå™¨): ").strip() or "è®¡ç®—æœºéšæœºæ•°ç”Ÿæˆå™¨"
        data['blinding'] = input("æ˜¯å¦é‡‡ç”¨ç›²æ³• (Yes/No): ").strip() or "Yes"
        if data['blinding'].lower() == 'yes':
            data['blinding_details'] = input("ç›²æ³•å®æ–½ç»†èŠ‚ (è°ã€ä½•æ—¶ã€å¦‚ä½•): ").strip() or "å®éªŒæ“ä½œè€…å’Œç»“å±€è¯„ä¼°è€…å‡ä¸çŸ¥æ™“åˆ†ç»„æƒ…å†µ"
        
        # ç»“å±€æŒ‡æ ‡
        print("\nã€ç¬¬äº”æ­¥ã€‘ç»“å±€æŒ‡æ ‡ (Item 6)")
        print("-" * 40)
        data['primary_endpoint'] = input("ä¸»è¦ç»“å±€æŒ‡æ ‡: ").strip()
        
        secondary = input("æ¬¡è¦ç»“å±€æŒ‡æ ‡ (ç”¨é€—å·åˆ†éš”): ").strip()
        data['secondary_endpoints'] = [s.strip() for s in secondary.split(",") if s.strip()]
        
        # ç»Ÿè®¡åˆ†æ
        print("\nã€ç¬¬å…­æ­¥ã€‘ç»Ÿè®¡æ–¹æ³• (Item 7)")
        print("-" * 40)
        data['statistical_method'] = input(
            "ä¸»è¦ç»Ÿè®¡æ–¹æ³• (å¦‚: One-way ANOVA + Tukey's post-hoc): ").strip() or "One-way ANOVA"
        
        # å®éªŒç¨‹åº
        print("\nã€ç¬¬ä¸ƒæ­¥ã€‘å®éªŒç¨‹åº (Item 9)")
        print("-" * 40)
        data['study_duration'] = input("å®éªŒå‘¨æœŸ (å¤©): ").strip()
        data['dosing_route'] = input("ç»™è¯é€”å¾„ (å¦‚: çŒèƒƒ/è…¹è…”æ³¨å°„/é™è„‰æ³¨å°„): ").strip() or "çŒèƒƒ"
        data['dosing_frequency'] = input("ç»™è¯é¢‘ç‡ (å¦‚: æ¯æ—¥ä¸€æ¬¡/æ¯å‘¨ä¸‰æ¬¡): ").strip() or "æ¯æ—¥ä¸€æ¬¡"
        
        # ä¼¦ç†
        print("\nã€ç¬¬å…«æ­¥ã€‘ä¼¦ç†ä¸ç¦åˆ©")
        print("-" * 40)
        data['ethical_approval'] = input("ä¼¦ç†å§”å‘˜ä¼šåç§°: ").strip()
        data['approval_number'] = input("æ‰¹å‡†ç¼–å·: ").strip()
        data['housing_conditions'] = input("é¥²å…»æ¡ä»¶ (å¦‚: SPFçº§, æ¸©åº¦22Â±2Â°C, æ¹¿åº¦50Â±10%): ").strip() or "SPFçº§ç¯å¢ƒ"
        
        self.protocol_data = data
        return data
    
    def generate_protocol(self, data: Optional[Dict] = None, output_format: str = "markdown") -> str:
        """ç”Ÿæˆå®Œæ•´å®éªŒæ–¹æ¡ˆ"""
        if data is None:
            data = self.protocol_data
        
        if output_format == "markdown":
            return self._generate_markdown_protocol(data)
        else:
            return self._generate_text_protocol(data)
    
    def _generate_markdown_protocol(self, data: Dict) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼å®éªŒæ–¹æ¡ˆ"""
        md = []
        
        # æ ‡é¢˜
        md.append(f"# {data.get('title', 'åŠ¨ç‰©å®éªŒæ–¹æ¡ˆ')}")
        md.append(f"\n> æœ¬æ–¹æ¡ˆä¸¥æ ¼éµå¾ª ARRIVE 2.0 æŒ‡å—è®¾è®¡")
        md.append(f"> ç”Ÿæˆæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}\n")
        
        # 1. Study Design
        md.append("## 1. ç ”ç©¶è®¾è®¡ (Study Design)\n")
        md.append(f"**å®éªŒç±»å‹**: {self.STUDY_TEMPLATES.get(data.get('study_type', 'efficacy'), {}).get('name', 'è‡ªå®šä¹‰ç ”ç©¶')}\n")
        md.append(f"**å®éªŒç»„æ•°**: {len(data.get('groups', []))}")
        md.append(f"**æ¯ç»„åŠ¨ç‰©æ•°**: {data.get('sample_size_per_group', 'N/A')}")
        md.append(f"**æ€»åŠ¨ç‰©æ•°**: {data.get('total_animals', 'N/A')}\n")
        
        md.append("### å®éªŒåˆ†ç»„")
        md.append("| ç»„åˆ« | å¤„ç†æ–¹å¼ | åŠ¨ç‰©æ•° |")
        md.append("|------|----------|--------|")
        for group in data.get('groups', []):
            md.append(f"| {group.get('name', 'N/A')} | {group.get('treatment', 'N/A')} | {data.get('sample_size_per_group', 'N/A')} |")
        md.append("")
        
        md.append(f"**ç›²æ³•å®æ–½**: {data.get('blinding', 'No')}")
        if data.get('blinding_details'):
            md.append(f"**ç›²æ³•ç»†èŠ‚**: {data['blinding_details']}")
        md.append("")
        
        # 2. Sample Size
        md.append("## 2. æ ·æœ¬é‡è®¡ç®— (Sample Size)\n")
        md.append("æ ·æœ¬é‡åŸºäºä»¥ä¸‹å‚æ•°è®¡ç®—:\n")
        md.append(f"- **é¢„æœŸæ•ˆåº”é‡ (Effect size)**: {data.get('effect_size', 'N/A')}")
        md.append(f"- **æ£€éªŒæ•ˆèƒ½ (Power, 1-Î²)**: {data.get('power', '0.80')}")
        md.append(f"- **æ˜¾è‘—æ€§æ°´å¹³ (Î±)**: {data.get('alpha', '0.05')}")
        md.append(f"- **æœ€ç»ˆæ¯ç»„åŠ¨ç‰©æ•°**: {data.get('sample_size_per_group', 'N/A')} (è€ƒè™‘10%è„±è½ç‡)\n")
        
        # 3. Inclusion/Exclusion
        md.append("## 3. çº³å…¥ä¸æ’é™¤æ ‡å‡† (Inclusion/Exclusion Criteria)\n")
        md.append("### çº³å…¥æ ‡å‡†")
        md.append(f"- ç‰©ç§: {data.get('species', 'N/A')}")
        md.append(f"- å“ç³»: {data.get('strain', 'N/A')}")
        md.append(f"- æ€§åˆ«: {data.get('sex', 'N/A')}")
        md.append(f"- å¹´é¾„: {data.get('age', 'N/A')}")
        md.append(f"- ä½“é‡èŒƒå›´: {data.get('weight_range', 'N/A')}")
        md.append("- å¥åº·çŠ¶æ€: æ— å¯è§ç–¾ç—…ä½“å¾\n")
        
        md.append("### æ’é™¤æ ‡å‡†")
        md.append("- å®éªŒå‰å‡ºç°å¼‚å¸¸å¥åº·çŠ¶å†µ")
        md.append("- ç»™è¯æœŸé—´æ„å¤–æ­»äº¡ï¼ˆéœ€è¿›è¡Œå°¸æ£€ï¼‰")
        md.append("- æ ·æœ¬é‡‡é›†å¤±è´¥\n")
        
        # 4. Randomisation
        md.append("## 4. éšæœºåŒ–æ–¹æ¡ˆ (Randomisation)\n")
        md.append(f"**éšæœºåŒ–æ–¹æ³•**: {data.get('randomization_method', 'è®¡ç®—æœºéšæœºæ•°ç”Ÿæˆå™¨')}")
        md.append("- åŠ¨ç‰©æŒ‰ä½“é‡åˆ†å±‚åéšæœºåˆ†é…è‡³å„ç»„")
        md.append("- ä½¿ç”¨SPSS/R/Pythonç”Ÿæˆéšæœºæ•°å­—")
        md.append("- éšæœºåŒ–ç”±ç‹¬ç«‹äºå®éªŒæ“ä½œçš„äººå‘˜æ‰§è¡Œ\n")
        
        # 5. Blinding
        md.append("## 5. ç›²æ³• (Blinding)\n")
        if data.get('blinding', 'No').lower() == 'yes':
            md.append("| é˜¶æ®µ | çŸ¥æƒ…äººå‘˜ | è¯´æ˜ |")
            md.append("|------|----------|------|")
            md.append("| åˆ†ç»„åˆ†é… | ä»…éšæœºåŒ–æ‰§è¡Œè€… | åˆ†é…æ–¹æ¡ˆå¯†å°ä¿å­˜ |")
            md.append("| å®éªŒæ“ä½œ | æ“ä½œè€…ä¸çŸ¥æƒ… | è¯ç‰©ç¼–å·å¤„ç† |")
            md.append("| ç»“å±€è¯„ä¼° | è¯„ä¼°è€…ä¸çŸ¥æƒ… | ç‹¬ç«‹è¯„ä¼° |")
            md.append("| æ•°æ®åˆ†æ | åˆ†æè€…ä¸çŸ¥æƒ… | æŒ‰ç»„åˆ«ç¼–ç åˆ†æ |")
        else:
            md.append("æœ¬å®éªŒé‡‡ç”¨å¼€æ”¾æ ‡ç­¾è®¾è®¡ï¼Œä¸è®¾ç›²æ³•ã€‚")
        md.append("")
        
        # 6. Outcome Measures
        md.append("## 6. ç»“å±€æŒ‡æ ‡ (Outcome Measures)\n")
        md.append(f"**ä¸»è¦ç»“å±€æŒ‡æ ‡**: {data.get('primary_endpoint', 'N/A')}")
        md.append("\n**æ¬¡è¦ç»“å±€æŒ‡æ ‡**:")
        for endpoint in data.get('secondary_endpoints', []):
            md.append(f"- {endpoint}")
        md.append("")
        
        # 7. Statistical Methods
        md.append("## 7. ç»Ÿè®¡æ–¹æ³• (Statistical Methods)\n")
        md.append(f"**ä¸»è¦åˆ†ææ–¹æ³•**: {data.get('statistical_method', 'One-way ANOVA')}")
        md.append("- æ­£æ€æ€§æ£€éªŒ: Shapiro-Wilk test")
        md.append("- æ–¹å·®é½æ€§æ£€éªŒ: Levene's test")
        md.append("- å¤šé‡æ¯”è¾ƒæ ¡æ­£: Tukey's HSD æˆ– Bonferroni")
        md.append("- æ˜¾è‘—æ€§æ°´å¹³: Î± = 0.05 (åŒä¾§)")
        md.append("- è½¯ä»¶: GraphPad Prism 9.0 æˆ– SPSS 26.0\n")
        
        # 8. Experimental Animals
        md.append("## 8. å®éªŒåŠ¨ç‰© (Experimental Animals)\n")
        md.append(f"| å‚æ•° | è¯¦æƒ… |")
        md.append(f"|------|------|")
        md.append(f"| ç‰©ç§ | {data.get('species', 'N/A')} |")
        md.append(f"| å“ç³» | {data.get('strain', 'N/A')} |")
        md.append(f"| æ€§åˆ« | {data.get('sex', 'N/A')} |")
        md.append(f"| å¹´é¾„ | {data.get('age', 'N/A')} |")
        md.append(f"| ä½“é‡ | {data.get('weight_range', 'N/A')} |")
        md.append(f"| æ¥æº | {data.get('source', 'N/A')} |")
        md.append(f"| é¥²å…»æ¡ä»¶ | {data.get('housing_conditions', 'SPFçº§')} |")
        md.append("")
        
        # 9. Experimental Procedures
        md.append("## 9. å®éªŒç¨‹åº (Experimental Procedures)\n")
        md.append(f"**å®éªŒå‘¨æœŸ**: {data.get('study_duration', 'N/A')} å¤©")
        md.append(f"**ç»™è¯é€”å¾„**: {data.get('dosing_route', 'N/A')}")
        md.append(f"**ç»™è¯é¢‘ç‡**: {data.get('dosing_frequency', 'N/A')}")
        md.append("**æ ·æœ¬é‡‡é›†**: æ ¹æ®å®éªŒç»ˆç‚¹é‡‡é›†è¡€æ¶²ã€ç»„ç»‡æ ·æœ¬")
        md.append("**å®‰ä¹æ­»æ–¹æ³•**: COâ‚‚ çª’æ¯æˆ–è¿‡é‡æˆŠå·´æ¯”å¦¥é’ \n")
        
        md.append("### å®éªŒæµç¨‹å›¾")
        md.append("```")
        md.append("Day 0: åŠ¨ç‰©é€‚åº” â†’ éšæœºåˆ†ç»„ â†’ åŸºçº¿æµ‹é‡")
        md.append("Day 1-28: æ¯æ—¥ç»™è¯ â†’ ä½“é‡ç›‘æµ‹ â†’ è¡Œä¸ºè§‚å¯Ÿ")
        md.append("Day 28: ç»ˆæœ«æµ‹é‡ â†’ æ ·æœ¬é‡‡é›† â†’ å®‰ä¹æ­»")
        md.append("```\n")
        
        # 10. Results (Template)
        md.append("## 10. é¢„æœŸç»“æœæŠ¥å‘Šæ¨¡æ¿ (Results)\n")
        md.append("_æ³¨: ä»¥ä¸‹ä¸ºç»“æœæŠ¥å‘Šæ¨¡æ¿ï¼Œå®éªŒå®Œæˆåå¡«å†™_\n")
        md.append("### ä¸»è¦ç»“å±€æŒ‡æ ‡")
        md.append("| ç»„åˆ« | N | Mean Â± SD | 95% CI | På€¼ (vs å¯¹ç…§) |")
        md.append("|------|---|-----------|--------|---------------|")
        for group in data.get('groups', []):
            md.append(f"| {group.get('name', 'N/A')} | | | | |")
        md.append("")
        
        md.append("### ç»Ÿè®¡åˆ†æ")
        md.append("- æ­£æ€æ€§æ£€éªŒç»“æœ: ")
        md.append("- æ–¹å·®åˆ†æç»“æœ: F(df1, df2) = _, P = _")
        md.append("- äº‹åæ£€éªŒç»“æœ: ")
        md.append("- æ•ˆåº”é‡ (Cohen's d): \n")
        
        # Additional Information
        md.append("## 11. ä¼¦ç†ä¸ç¦åˆ©\n")
        md.append(f"**ä¼¦ç†å§”å‘˜ä¼š**: {data.get('ethical_approval', 'å¾…å¡«å†™')}")
        md.append(f"**æ‰¹å‡†ç¼–å·**: {data.get('approval_number', 'å¾…å¡«å†™')}")
        md.append("**åŠ¨ç‰©ç¦åˆ©**: å®éªŒéµå¾ª3RåŸåˆ™ï¼Œå°½é‡å‡å°‘åŠ¨ç‰©ç—›è‹¦å’Œæ•°é‡")
        md.append("**äººé“ç»ˆæœ«ç‚¹**: ä½“é‡ä¸‹é™>20%ã€ä¸¥é‡è¡Œä¸ºå¼‚å¸¸ã€æ— æ³•è¿›é£Ÿé¥®æ°´\n")
        
        # ARRIVE Checklist
        md.append("---\n")
        md.append("# ARRIVE 2.0 åˆè§„æ£€æŸ¥æ¸…å•\n")
        md.append("| é¡¹ç›® | å†…å®¹ | æ˜¯å¦å®Œæˆ | é¡µç  |")
        md.append("|------|------|----------|------|")
        for item, details in self.ESSENTIAL_10.items():
            md.append(f"| {item} | {details['description'][:50]}... | â˜ | |")
        md.append("")
        
        md.append("---\n*æœ¬æ–¹æ¡ˆç”± ARRIVE Guideline Architect è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(md)
    
    def _generate_text_protocol(self, data: Dict) -> str:
        """ç”Ÿæˆçº¯æ–‡æœ¬æ ¼å¼å®éªŒæ–¹æ¡ˆ"""
        return self._generate_markdown_protocol(data).replace('#', '').replace('|', '').replace('-', '')
    
    def generate_checklist(self, format_type: str = "markdown") -> str:
        """ç”Ÿæˆ ARRIVE 2.0 æ£€æŸ¥æ¸…å•"""
        lines = []
        lines.append("# ARRIVE 2.0 Essential 10 æ£€æŸ¥æ¸…å•\n")
        lines.append(f"æ£€æŸ¥æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}\n")
        
        for item, details in self.ESSENTIAL_10.items():
            lines.append(f"## {item}")
            lines.append(f"æè¿°: {details['description']}\n")
            lines.append("æ£€æŸ¥è¦ç‚¹:")
            for checkpoint in details['checkpoints']:
                lines.append(f"  â˜ {checkpoint}")
            lines.append("")
        
        lines.append("\n# Recommended Set æ£€æŸ¥æ¸…å•\n")
        for item, description in self.RECOMMENDED_SET.items():
            lines.append(f"## {item}")
            lines.append(f"  â˜ {description}\n")
        
        return "\n".join(lines)
    
    def validate_protocol(self, protocol_text: str) -> Dict[str, Any]:
        """éªŒè¯å®éªŒæ–¹æ¡ˆæ˜¯å¦ç¬¦åˆ ARRIVE 2.0 æ ‡å‡†"""
        results = {
            "score": 0,
            "max_score": len(self.ESSENTIAL_10),
            "compliance": {},
            "recommendations": []
        }
        
        text_lower = protocol_text.lower()
        
        # æ£€æŸ¥ Essential 10 å„é¡¹
        checks = {
            "1. Study Design": ["group", "design", "blind"],
            "2. Sample Size": ["sample size", "power", "effect size", "significance"],
            "3. Inclusion/Exclusion Criteria": ["inclusion", "exclusion", "criteria"],
            "4. Randomisation": ["random", "allocation"],
            "5. Blinding": ["blind", "mask"],
            "6. Outcome Measures": ["outcome", "primary", "secondary", "endpoint"],
            "7. Statistical Methods": ["statistical", "analysis", "anova", "t-test"],
            "8. Experimental Animals": ["species", "strain", "age", "weight", "source"],
            "9. Experimental Procedures": ["procedure", "treatment", "dosing", "administration"],
            "10. Results": ["result", "mean", "sd", "sem", "confidence interval"]
        }
        
        for item, keywords in checks.items():
            found = any(kw in text_lower for kw in keywords)
            results["compliance"][item] = found
            if found:
                results["score"] += 1
            else:
                results["recommendations"].append(f"ç¼ºå°‘ {item} ç›¸å…³å†…å®¹")
        
        results["percentage"] = round(results["score"] / results["max_score"] * 100, 1)
        
        return results
    
    def save_protocol(self, content: str, filepath: str):
        """ä¿å­˜æ–¹æ¡ˆåˆ°æ–‡ä»¶"""
        path = Path(filepath)
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… æ–¹æ¡ˆå·²ä¿å­˜è‡³: {filepath}")


def main():
    parser = argparse.ArgumentParser(
        description="ARRIVE Guideline Architect - åŸºäº ARRIVE 2.0 æ ‡å‡†è®¾è®¡åŠ¨ç‰©å®éªŒæ–¹æ¡ˆ"
    )
    parser.add_argument("--interactive", "-i", action="store_true", 
                        help="äº¤äº’å¼å®éªŒè®¾è®¡å‘å¯¼")
    parser.add_argument("--input", "-in", type=str,
                        help="è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", type=str, default="protocol.md",
                        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: protocol.md)")
    parser.add_argument("--validate", "-v", type=str,
                        help="éªŒè¯ç°æœ‰æ–¹æ¡ˆæ–‡ä»¶")
    parser.add_argument("--checklist", "-c", action="store_true",
                        help="ç”Ÿæˆ ARRIVE 2.0 æ£€æŸ¥æ¸…å•")
    parser.add_argument("--format", "-f", type=str, default="markdown",
                        choices=["markdown", "text"],
                        help="è¾“å‡ºæ ¼å¼")
    
    args = parser.parse_args()
    
    architect = ARRIVEGuidelineArchitect()
    
    if args.checklist:
        # ç”Ÿæˆæ£€æŸ¥æ¸…å•
        checklist = architect.generate_checklist(args.format)
        architect.save_protocol(checklist, args.output)
        print("\nğŸ“‹ ARRIVE 2.0 æ£€æŸ¥æ¸…å•å·²ç”Ÿæˆ!")
        
    elif args.validate:
        # éªŒè¯ç°æœ‰æ–¹æ¡ˆ
        try:
            with open(args.validate, 'r', encoding='utf-8') as f:
                protocol_text = f.read()
            
            results = architect.validate_protocol(protocol_text)
            
            print(f"\n{'='*50}")
            print("ARRIVE 2.0 åˆè§„æ€§éªŒè¯æŠ¥å‘Š")
            print(f"{'='*50}")
            print(f"\nåˆè§„å¾—åˆ†: {results['score']}/{results['max_score']} ({results['percentage']}%)")
            
            print("\né€é¡¹æ£€æŸ¥ç»“æœ:")
            for item, compliant in results['compliance'].items():
                status = "âœ…" if compliant else "âŒ"
                print(f"  {status} {item}")
            
            if results['recommendations']:
                print("\næ”¹è¿›å»ºè®®:")
                for rec in results['recommendations']:
                    print(f"  â€¢ {rec}")
            else:
                print("\nğŸ‰ æ­å–œï¼æ‚¨çš„æ–¹æ¡ˆç¬¦åˆ ARRIVE 2.0 æ‰€æœ‰å¿…éœ€é¡¹è¦æ±‚ï¼")
                
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {args.validate}")
            sys.exit(1)
            
    elif args.input:
        # ä»æ–‡ä»¶ç”Ÿæˆæ–¹æ¡ˆ
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            protocol = architect.generate_protocol(data, args.format)
            architect.save_protocol(protocol, args.output)
            print(f"\nâœ… å®éªŒæ–¹æ¡ˆå·²ç”Ÿæˆ: {args.output}")
            
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {args.input}")
            sys.exit(1)
        except json.JSONDecodeError:
            print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")
            sys.exit(1)
            
    elif args.interactive:
        # äº¤äº’å¼å‘å¯¼
        data = architect.interactive_design()
        protocol = architect.generate_protocol(data, args.format)
        architect.save_protocol(protocol, args.output)
        
        print(f"\n{'='*50}")
        print("âœ… å®éªŒæ–¹æ¡ˆè®¾è®¡å®Œæˆ!")
        print(f"{'='*50}")
        print(f"\næ–‡ä»¶ä¿å­˜ä½ç½®: {args.output}")
        print(f"æ€»åŠ¨ç‰©æ•°: {data.get('total_animals', 'N/A')}")
        print(f"å®éªŒç»„æ•°: {len(data.get('groups', []))}")
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. å°†æ–¹æ¡ˆæäº¤ç»™æœºæ„ä¼¦ç†å§”å‘˜ä¼šå®¡æ‰¹")
        print("  2. æ ¹æ®æ–¹æ¡ˆè¿›è¡Œé¢„å®éªŒéªŒè¯")
        print("  3. ä½¿ç”¨ --validate éªŒè¯æœ€ç»ˆæ–¹æ¡ˆå®Œæ•´æ€§")
        
    else:
        # æ˜¾ç¤ºå¸®åŠ©
        parser.print_help()
        print("\nğŸ’¡ æç¤º: ä½¿ç”¨ --interactive å¯åŠ¨äº¤äº’å¼å‘å¯¼")


if __name__ == "__main__":
    main()
