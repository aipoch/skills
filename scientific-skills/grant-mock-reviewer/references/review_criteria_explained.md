# Review Criteria Explained

## Detailed Explanation of NIH Review Criteria

This document provides in-depth explanation of each NIH review criterion to help reviewers apply scores consistently and applicants understand expectations.

---

## Significance

### What Reviewers Look For

1. **Problem Identification**
   - Is the research question clearly stated?
   - Is the problem framed appropriately for the field?
   - Does it address a meaningful gap?

2. **Knowledge Gap**
   - Is the gap clearly articulated?
   - Is the gap real (not already filled)?
   - Is the gap important to fill?

3. **Potential Impact**
   - Will answering this question advance the field?
   - Could findings be translated to clinical practice?
   - Does it have public health relevance?

### Common Issues

| Issue | Impact | How to Address |
|-------|--------|----------------|
| Incremental advance | Score ↑ | Emphasize transformative potential |
| Overstated significance | Score ↑ | Provide evidence for claims |
| Unclear clinical relevance | Score ↑ | Connect to human health clearly |
| Already-answered question | Score ↑↑ | Conduct thorough literature review |
| Too broad focus | Score ↑ | Narrow scope appropriately |

### Strengths to Highlight

- Addresses a critical barrier to progress
- Has potential to change clinical practice
- Advances a high-priority research area
- Could benefit underserved populations
- Fills a clearly defined knowledge gap

---

## Investigator(s)

### What Reviewers Look For

1. **Expertise Match**
   - Does the PI have the right training?
   - Is their publication record relevant?
   - Have they used proposed methods before?

2. **Track Record**
   - Productivity (publications, funding)
   - Scientific contributions
   - Innovation in previous work
   - Training record (for senior PIs)

3. **Team Composition**
   - Are all needed skills represented?
   - Are collaborators appropriate?
   - Are consultants identified if needed?

4. **Time Commitment**
   - Is the PI's effort reasonable?
   - Are they overcommitted on other grants?
   - Is there evidence of dedicated time?

### Common Issues

| Issue | Impact | How to Address |
|-------|--------|----------------|
| PI overcommitted (>6 major grants) | Score ↑↑ | Reduce effort or add MPI |
| Missing method expertise | Score ↑ | Add collaborator with expertise |
| Early career without mentorship | Score ↑ | Strengthen mentoring plan |
| No relevant publications | Score ↑↑ | Gain preliminary experience |
| Weak institutional support | Score ↑ | Document institutional commitment |

### Investigator Score Factors

**Score 1-3**: Distinguished track record, perfect match, strong team
**Score 4-5**: Good track record, adequate match, competent team
**Score 6-7**: Limited record, partial mismatch, weak team
**Score 8-9**: Inexperienced, poor match, inadequate team

---

## Innovation

### What Reviewers Look For

1. **Novel Concepts**
   - Does it challenge existing paradigms?
   - Are theoretical frameworks new?
   - Does it propose new models?

2. **Novel Approaches**
   - Are methods innovative?
   - Is there creative integration of approaches?
   - Are existing methods applied in new ways?

3. **Novel Technologies**
   - Are new tools being developed?
   - Is cutting-edge technology applied?
   - Are instruments used creatively?

### Innovation vs. Risk

| Level | Description | Score Implication |
|-------|-------------|-------------------|
| High Innovation + Feasible | Paradigm shift with solid foundation | Score ↓↓↓ (excellent) |
| High Innovation + Unproven | Risky but potentially transformative | Score ↑ (needs strong support) |
| Low Innovation + Proven | Safe but incremental | Score ↑ (limited novelty) |
| Low Innovation + Unproven | Worst of both | Score ↑↑ (not innovative AND risky) |

### Common Issues

- Claims of novelty without evidence
- "Novel" methods that are standard in the field
- Innovation at the expense of feasibility
- Incremental advances described as breakthroughs

### Demonstrating Innovation

1. Clearly state what is innovative
2. Contrast with current state-of-the-art
3. Cite literature showing this hasn't been done
4. Explain why this innovation matters
5. Provide preliminary data supporting feasibility

---

## Approach

### What Reviewers Look For

1. **Research Design**
   - Are hypotheses clearly stated?
   - Are aims logically connected?
   - Is the design appropriate for the question?

2. **Methods**
   - Are techniques appropriate and current?
   - Are alternatives considered?
   - Are positive and negative controls included?

3. **Analysis Plan**
   - Is statistical analysis appropriate?
   - Are power calculations provided?
   - Is the analysis plan fully described?

4. **Preliminary Data**
   - Do data support feasibility?
   - Is there evidence the methods work?
   - Do data support the hypothesis?

5. **Risk Management**
   - Are potential pitfalls identified?
   - Are alternative approaches described?
   - Are there go/no-go criteria?

### Statistical Considerations

| Element | Required | Common Weakness |
|---------|----------|-----------------|
| Sample size justification | Yes | Power calculation missing |
| Statistical tests specified | Yes | "Appropriate tests will be used" |
| Handling of missing data | Yes | Not addressed |
| Multiplicity adjustment | If applicable | Multiple comparisons not corrected |
| Effect size estimation | Yes | Only p-values mentioned |

### Timeline and Feasibility

A typical R01 timeline (4-5 years):

- **Year 1**: Method optimization, recruitment initiation
- **Year 2**: Active data collection, initial analysis
- **Year 3**: Continued collection, analysis, potential adjustments
- **Year 4**: Final data collection, comprehensive analysis
- **Year 5**: Final analysis, publication, preparation for next phase

### Common Approach Weaknesses

1. **Aims too ambitious**
   - Cannot be completed in timeframe
   - Insufficient personnel
   - Unrealistic recruitment targets

2. **Insufficient preliminary data**
   - No evidence methods work
   - Key feasibility questions unanswered
   - Missing critical pilot data

3. **Weak experimental design**
   - Inadequate controls
   - Confounding not addressed
   - Bias not minimized

4. **Inadequate alternatives**
   - No Plan B for risky experiments
   - No consideration of what could go wrong
   - No exit strategy if aims fail

---

## Environment

### What Reviewers Look For

1. **Institutional Resources**
   - Core facilities access
   - Equipment availability
   - Administrative support
   - Training programs

2. **Scientific Environment**
   - Colleagues in related fields
   - Collaborative opportunities
   - Seminar series
   - Research culture

3. **Special Resources**
   - Access to patient populations
   - Unique equipment
   - Special facilities
   - Geographic advantages

### Documenting Environment

Include information about:

- Institutional commitment letter
- Core facility descriptions and access
- Major equipment lists
- Collaborative arrangements
- Special population access

### Environmental Score Factors

**Score 1-3**: Outstanding resources, unique environment, exceptional support
**Score 4-5**: Adequate resources, supportive environment, good access
**Score 6-7**: Limited resources, challenging environment, restricted access
**Score 8-9**: Inadequate resources, unsupportive environment, no required access

---

## Overall Impact

### Definition

The Overall Impact Score reflects the reviewer's assessment of the likelihood for the project to exert a sustained, powerful influence on the research field(s) involved.

### How It's Determined

Overall Impact is **NOT** an average of the five criterion scores. Instead:

1. **Approach** typically carries the most weight
2. **Significance** and **Innovation** are often weighted equally
3. **Investigator** and **Environment** provide context

### Weighting Considerations

| If Approach is... | Overall Impact tends to be... |
|-------------------|------------------------------|
| 1-2 (Excellent) | Boosted toward 1-3 |
| 4-5 (Good) | Around 4-5 |
| 7-9 (Weak) | Pulled toward 6-9 regardless of other scores |

### Balancing Criteria

**High Overall Impact** typically requires:
- Significance: 1-4 (important problem)
- Investigator: 1-5 (well-qualified)
- Innovation: 1-5 (some novelty)
- Approach: 1-4 (sound design)
- Environment: 1-5 (adequate support)

**Low Overall Impact** often results from:
- Fatal flaw in Approach (regardless of other scores)
- Poor Significance (trivial problem)
- Unqualified Investigator
- Inadequate Environment for the proposed work

---

## Summary Statement Structure

A typical NIH Summary Statement includes:

1. **Overall Impact Score**
2. **Criterion Scores** (1-9 each)
3. **Resume and Summary of Discussion**
4. **Critique** (strengths and weaknesses by criterion)
5. **Additional Comments** (if applicable)

### Resume and Summary

This narrative section (typically 1 paragraph) captures:
- Brief project description
- Major strengths
- Major weaknesses
- Reasons for enthusiasm (or lack thereof)

Example:

> "This application from Dr. Smith at State University proposes to investigate the role of protein X in disease Y using a combination of in vitro and in vivo approaches. The PI has an excellent track record in this area and has assembled a strong team. Preliminary data support the feasibility of the proposed aims. However, the approach for Aim 2 is underdeveloped and the sample size calculations appear inadequate. Innovation is limited. Overall, this is a good application with some concerns about the approach."

---

## Review Ethics and Bias

### Conflicts of Interest

Reviewers must declare and avoid:
- Financial conflicts
- Personal relationships
- Recent collaborations
- Institutional conflicts

### Unconscious Bias

Reviewers should be aware of:
- Gender bias
- Racial/ethnic bias
- Institutional bias (prestige bias)
- Age bias
- Geographic bias

### Fair Assessment

All applications should be evaluated:
- On their scientific merit
- Without regard to institution
- Based on what's proposed, not who's proposing
- Using consistent standards
